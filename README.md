# ğŸ§  XunZi: An AI Biologist for Mechanism-Guided Therapeutic Target Discovery

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=PyTorch&logoColor=white)](https://pytorch.org/)

## ğŸ” Overview

XunZi is an AI-driven framework that bridges mechanistic insights from biomedical literature with multi-omics data for therapeutic target discovery. It consists of two synergistic modules:

- **XunZi-M**: Multi-omics learning module integrating >600TB of biological data
- **XunZi-R**: Mechanistic reasoning engine based on Mistral-7B, trained on 24M biomedical publications

## ğŸ“Š Key Features

- **Continual Pre-training**: Custom biomedical language model trained on 240,000+ curated publications
- **Multi-modal Integration**: Combines graph neural networks with transformer-based reasoning
- **Scalable Architecture**: Distributed training support with LoRA for efficient fine-tuning
- **Comprehensive Evaluation**: Multiple metrics including perplexity, ROUGE, BLEU, and entity extraction F1

## ğŸ—ï¸ Repository Structure
```
XunZi/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py              # Dataset classes for biomedical text
â”‚   â”‚   â”œâ”€â”€ preprocessor.py         # Text preprocessing for gene-disease annotations
â”‚   â”‚   â””â”€â”€ preprocess_data.py      # Main data preprocessing pipeline
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ mistral_wrapper.py      # Mistral-7B model wrapper with LoRA
â”‚   â”‚   â””â”€â”€ XunZi_modules/           # XunZi-M and XunZi-R implementations
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py               # Distributed training orchestration
â”‚   â”‚   â””â”€â”€ train.py                 # Main training script
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ evaluator.py            # Comprehensive evaluation framework
â”‚       â”œâ”€â”€ metrics.py               # Biomedical-specific metrics
â”‚       â””â”€â”€ inference.py             # Inference engine for deployment
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_data.py          # Data preparation scripts
â”‚   â”œâ”€â”€ train.py                     # Training launcher
â”‚   â””â”€â”€ evaluate/
â”‚       â”œâ”€â”€ evaluate_model.py       # Model evaluation
â”‚       â””â”€â”€ benchmark.py             # Performance benchmarking
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml        # Training hyperparameters
â”‚   â””â”€â”€ eval_config.yaml            # Evaluation settings
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ XunZi-R/                    # Reasoning module checkpoints
â”‚   â””â”€â”€ XunZi-M/                    # Multi-omics module checkpoints
â”œâ”€â”€ demo_data/                       # Example datasets
â”œâ”€â”€ demo_xunzi.py                    # End-to-end demonstration
â”œâ”€â”€ demo_xunzi_r.py                  # XunZi-R standalone demo
â”œâ”€â”€ demo_xunzi_l.py                  # XunZi-M standalone demo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ’» System Requirements

| Component | Requirement |
|-----------|------------|
| **Python** | 3.8+ |
| **PyTorch** | 2.0+ |
| **CUDA** | 11.8+ (for GPU) |
| **RAM** | 64GB+ |
| **GPU** | 24GB+ VRAM (RTX 3090/4090, A100) |
| **Storage** | 100GB+ for full dataset |

## ğŸš€ Quick Start

### 1. Installation
```bash
# Clone repository
git clone https://github.com/biocuckooHXH/XunZi.git
cd XunZi

# Create conda environment
conda create -n xunzi python=3.9
conda activate xunzi

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Pre-trained Models
```bash
# Download XunZi-R base model from HuggingFace
huggingface-cli download H2dddhxh/XunZi-R-BioPre --local-dir ./models/XunZi-R-BioPre

# Download XunZi-R adapter
huggingface-cli download H2dddhxh/XunZi-R --local-dir ./models/XunZi-R

# Download demo data
huggingface-cli download H2dddhxh/XunZi graph_data.pth --local-dir ./demo_data
```

### 3. Run Demo
```bash
# Quick demo with pre-trained models
python demo_xunzi.py \
  --graph_data ./demo_data/graph_data.pth \
  --model_id ./models/XunZi-R \
  --output_csv results/xunzi_predictions.csv
```

## ğŸ”§ Full Pipeline

### Data Preprocessing

Process raw biomedical literature (240,000 articles and gene-disease annotations):
```bash
python scripts/preprocess_data.py \
  --input-path /path/to/raw/articles.json \
  --output-dir data/processed \
  --tokenizer mistralai/Mistral-7B-Instruct-v0.1 \
  --task cpt \
  --max-length 2048 \
  --val-ratio 0.05
```

### Continual Pre-training

Train XunZi-R on biomedical corpus using LoRA:
```bash
python scripts/train.py \
  --config configs/training_config.yaml \
  --use-wandb
```


## ğŸ”¬ XunZi Modules

### XunZi-M: Multi-Omics Learning
- Graph Convolutional Networks for gene-gene interactions
- Integration of 600TB+ multi-omics data
- Cross-validation with DisGeNET and CTD databases

### XunZi-R: Mechanistic Reasoning
- Fine-tuned Mistral-7B on 24M publications
- Specialized for biomedical entity recognition
- Generates mechanistic hypotheses for gene-disease associations


## ğŸ“ Citation

If you use XunZi in your research, please cite:
```bibtex
@article{huang2024xunzi,
  title={XunZi, a AI biologist, reveals novel disease-modifying targets},
  author={Huang, Xinhe et al.},
  journal={bioRxiv},
  year={2024}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Mistral AI for the base language model
- DisGeNET and CTD for validation databases
- The biomedical research community for open datasets

## ğŸ“§ Contact

For questions and support:
- Open an issue on GitHub
- Email: huangxinhe@hust.edu.cn
